{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import","metadata":{}},{"cell_type":"code","source":"import os\nimport shutil\n\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport matplotlib.pyplot as plt\n\nimport logging\nimport sys\nimport tempfile\nfrom glob import glob\n\nimport torch\nfrom PIL import Image\nfrom torch.utils.data import DataLoader\nfrom torch.utils.tensorboard import SummaryWriter\n\n%cd ../input/monai-v070\nimport monai\nfrom monai.data import create_test_image_2d, list_data_collate, decollate_batch\nfrom monai.inferers import sliding_window_inference\nfrom monai.metrics import DiceMetric\nfrom monai.transforms import (\n    Activations,\n    AddChanneld,\n    AsDiscrete,\n    Compose,\n    LoadImaged,\n    RandCropByPosNegLabeld,\n    RandRotate90d,\n    ScaleIntensityd,\n    EnsureTyped,\n    EnsureType,\n)\nfrom monai.visualize import plot_2d_or_3d_image\n%cd ../../working","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-20T12:06:31.616014Z","iopub.execute_input":"2021-10-20T12:06:31.616886Z","iopub.status.idle":"2021-10-20T12:06:36.721164Z","shell.execute_reply.started":"2021-10-20T12:06:31.616764Z","shell.execute_reply":"2021-10-20T12:06:36.719748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nRESNET_MEAN = (0.485, 0.456, 0.406)\nRESNET_STD = (0.229, 0.224, 0.225)\n\n# (336, 336)\nIMAGE_RESIZE = (224, 224)\n\nLEARNING_RATE = 5e-4\nEPOCHS = 12","metadata":{"execution":{"iopub.status.busy":"2021-10-20T12:06:36.722773Z","iopub.execute_input":"2021-10-20T12:06:36.723021Z","iopub.status.idle":"2021-10-20T12:06:36.731168Z","shell.execute_reply.started":"2021-10-20T12:06:36.722992Z","shell.execute_reply":"2021-10-20T12:06:36.730059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir ../tmp\n!mkdir ../tmp/image\n\ntrain_csv = \"../input/sartorius-cell-instance-segmentation/train.csv\"\ntrain_path = \"../input/sartorius-cell-instance-segmentation/train\"\ntest_path = \"../input/sartorius-cell-instance-segmentation/test\"\n\ntmp_img_path = \"../tmp/image\"\n\ndf_train = pd.read_csv(train_csv)\nprint(df_train.head())\n\nimg_name = set()\nfor name in df_train['id']:\n    img_name.add(name)","metadata":{"execution":{"iopub.status.busy":"2021-10-20T12:06:36.733273Z","iopub.execute_input":"2021-10-20T12:06:36.733655Z","iopub.status.idle":"2021-10-20T12:06:38.902725Z","shell.execute_reply.started":"2021-10-20T12:06:36.733609Z","shell.execute_reply":"2021-10-20T12:06:38.901853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Utilities","metadata":{}},{"cell_type":"code","source":"# ref: https://www.kaggle.com/inversion/run-length-decoding-quick-start\ndef rle_decode(mask_rle, shape, color=1):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (height,width) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n\n    '''\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros((shape[0] * shape[1], shape[2]), dtype=np.float32)\n    for lo, hi in zip(starts, ends):\n        img[lo : hi] = color\n    return img.reshape(shape)\n\ndef rle_encode(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels = img.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\n\ndef build_masks(df_train, image_id, input_shape):\n    height, width = input_shape\n    labels = df_train[df_train[\"id\"] == image_id][\"annotation\"].tolist()\n    mask = np.zeros((height, width))\n    for label in labels:\n        mask += rle_decode(label, shape=(height, width))\n    mask = mask.clip(0, 1)\n    return mask\n\n\ndef flatten_l_o_l(nested_list):\n    \"\"\" Flatten a list of lists \"\"\"\n    return [item for sublist in nested_list for item in sublist]\n\n\ndef load_json_to_dict(json_path):\n    \"\"\" tbd \"\"\"\n    with open(json_path) as json_file:\n        data = json.load(json_file)\n    return data\n\n\ndef plot_masks(image_id, colors=True):\n    labels = df_train[df_train[\"id\"] == image_id][\"annotation\"].tolist()\n\n    if colors:\n        mask = np.zeros((520, 704, 3))\n        for label in labels:\n            mask += rle_decode(label, shape=(520, 704, 3), color=np.random.rand(3))\n    else:\n        mask = np.zeros((520, 704, 1))\n        for label in labels:\n            mask += rle_decode(label, shape=(520, 704, 1))\n    mask = mask.clip(0, 1)\n\n    image = cv2.imread(f\"../input/sartorius-cell-instance-segmentation/train/{image_id}.png\")\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n    plt.figure(figsize=(16, 32))\n    plt.subplot(3, 1, 1)\n    plt.imshow(image)\n    plt.axis(\"off\")\n    plt.subplot(3, 1, 2)\n    plt.imshow(image)\n    plt.imshow(mask, alpha=0.5)\n    plt.axis(\"off\")\n    plt.subplot(3, 1, 3)\n    plt.imshow(mask)\n    plt.axis(\"off\")\n    \n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-20T12:06:38.905209Z","iopub.execute_input":"2021-10-20T12:06:38.905448Z","iopub.status.idle":"2021-10-20T12:06:38.923414Z","shell.execute_reply.started":"2021-10-20T12:06:38.905416Z","shell.execute_reply":"2021-10-20T12:06:38.922461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_masks(\"ffdb3cc02eef\", colors=False)","metadata":{"execution":{"iopub.status.busy":"2021-10-20T12:06:38.925091Z","iopub.execute_input":"2021-10-20T12:06:38.925432Z","iopub.status.idle":"2021-10-20T12:06:40.02114Z","shell.execute_reply.started":"2021-10-20T12:06:38.925403Z","shell.execute_reply":"2021-10-20T12:06:40.020377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Make masking image","metadata":{}},{"cell_type":"code","source":"for img in img_name:\n    labels = df_train[df_train[\"id\"] == img][\"annotation\"].tolist()\n    mask = np.zeros((520, 704, 3))\n    for label in labels:\n        mask += rle_decode(label, shape=(520, 704, 1))\n    mask = mask.clip(0, 1)\n    \n    shutil.copy(f'../input/sartorius-cell-instance-segmentation/train/{img}.png', f'{tmp_img_path}/img_{img}.png')\n    cv2.imwrite(f'{tmp_img_path}/seg_{img}.png', mask)","metadata":{"execution":{"iopub.status.busy":"2021-10-20T12:32:41.162154Z","iopub.execute_input":"2021-10-20T12:32:41.16298Z","iopub.status.idle":"2021-10-20T12:36:03.353207Z","shell.execute_reply.started":"2021-10-20T12:32:41.162936Z","shell.execute_reply":"2021-10-20T12:36:03.352479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# DataLoader","metadata":{}},{"cell_type":"code","source":"monai.config.print_config()\nlogging.basicConfig(stream=sys.stdout, level=logging.INFO)\n\n# create a temporary directory and 40 random image, mask pairs\nprint(f\"generating synthetic data to {tmp_img_path} (this may take a while)\")\nfor img_id in img_name:\n    im, seg = create_test_image_2d(128, 128, num_seg_classes=1)\n    Image.fromarray((im * 255).astype(\"uint8\")).save(os.path.join(tmp_img_path, f\"img_{img_id}.png\"))\n    Image.fromarray((seg * 255).astype(\"uint8\")).save(os.path.join(tmp_img_path, f\"seg_{img_id}.png\"))\n\nimages = sorted(glob(os.path.join(tmp_img_path, \"*.png\")))\nsegs = sorted(glob(os.path.join(tmp_img_path, \"*.png\")))\ntrain_files = [{\"img\": img, \"seg\": seg} for img, seg in zip(images[:20], segs[:20])]\nval_files = [{\"img\": img, \"seg\": seg} for img, seg in zip(images[-20:], segs[-20:])]\n\n# define transforms for image and segmentation\ntrain_transforms = Compose(\n    [\n        LoadImaged(keys=[\"img\", \"seg\"]),\n        AddChanneld(keys=[\"img\", \"seg\"]),\n        ScaleIntensityd(keys=[\"img\", \"seg\"]),\n        RandCropByPosNegLabeld(\n            keys=[\"img\", \"seg\"], label_key=\"seg\", spatial_size=[96, 96], pos=1, neg=1, num_samples=4\n        ),\n        RandRotate90d(keys=[\"img\", \"seg\"], prob=0.5, spatial_axes=[0, 1]),\n        EnsureTyped(keys=[\"img\", \"seg\"]),\n    ]\n)\nval_transforms = Compose(\n    [\n        LoadImaged(keys=[\"img\", \"seg\"]),\n        AddChanneld(keys=[\"img\", \"seg\"]),\n        ScaleIntensityd(keys=[\"img\", \"seg\"]),\n        EnsureTyped(keys=[\"img\", \"seg\"]),\n    ]\n)\n\n# define dataset, data loader\ncheck_ds = monai.data.Dataset(data=train_files, transform=train_transforms)\n# use batch_size=2 to load images and use RandCropByPosNegLabeld to generate 2 x 4 images for network training\ncheck_loader = DataLoader(check_ds, batch_size=2, num_workers=4, collate_fn=list_data_collate)\ncheck_data = monai.utils.misc.first(check_loader)\nprint(check_data[\"img\"].shape, check_data[\"seg\"].shape)\n\n# create a training data loader\ntrain_ds = monai.data.Dataset(data=train_files, transform=train_transforms)\n# use batch_size=2 to load images and use RandCropByPosNegLabeld to generate 2 x 4 images for network training\ntrain_loader = DataLoader(\n    train_ds,\n    batch_size=2,\n    shuffle=True,\n    num_workers=4,\n    collate_fn=list_data_collate,\n    pin_memory=torch.cuda.is_available(),\n)\n# create a validation data loader\nval_ds = monai.data.Dataset(data=val_files, transform=val_transforms)\nval_loader = DataLoader(val_ds, batch_size=1, num_workers=4, collate_fn=list_data_collate)\ndice_metric = DiceMetric(include_background=True, reduction=\"mean\", get_not_nans=False)\npost_trans = Compose([EnsureType(), Activations(sigmoid=True), AsDiscrete(threshold_values=True)])","metadata":{"execution":{"iopub.status.busy":"2021-10-20T12:36:03.35468Z","iopub.execute_input":"2021-10-20T12:36:03.355083Z","iopub.status.idle":"2021-10-20T12:36:05.103618Z","shell.execute_reply.started":"2021-10-20T12:36:03.355042Z","shell.execute_reply":"2021-10-20T12:36:05.102975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"# create UNet, DiceLoss and Adam optimizer\nmodel = monai.networks.nets.UNet(\n    spatial_dims=2,\n    in_channels=3,\n    out_channels=1,\n    channels=(16, 32, 64, 128, 256),\n    strides=(2, 2, 2, 2),\n    num_res_units=2,\n).to(device)\nloss_function = monai.losses.DiceLoss(sigmoid=True)\noptimizer = torch.optim.Adam(model.parameters(), 1e-3)","metadata":{"execution":{"iopub.status.busy":"2021-10-20T12:36:05.105014Z","iopub.execute_input":"2021-10-20T12:36:05.105354Z","iopub.status.idle":"2021-10-20T12:36:05.141638Z","shell.execute_reply.started":"2021-10-20T12:36:05.105323Z","shell.execute_reply":"2021-10-20T12:36:05.140964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# train","metadata":{}},{"cell_type":"code","source":"# start a typical PyTorch training\nval_interval = 2\nbest_metric = -1\nbest_metric_epoch = -1\nepoch_loss_values = list()\nmetric_values = list()\n# writer = SummaryWriter()\nfor epoch in range(10):\n    print(\"-\" * 10)\n    print(f\"epoch {epoch + 1}/{10}\")\n    model.train()\n    epoch_loss = 0\n    step = 0\n    for batch_data in train_loader:\n        step += 1\n        inputs, labels = batch_data[\"img\"].to(device), batch_data[\"seg\"].to(device)\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = loss_function(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        epoch_loss += loss.item()\n        epoch_len = len(train_ds) // train_loader.batch_size\n        print(f\"{step}/{epoch_len}, train_loss: {loss.item():.4f}\")\n#         writer.add_scalar(\"train_loss\", loss.item(), epoch_len * epoch + step)\n    epoch_loss /= step\n    epoch_loss_values.append(epoch_loss)\n    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n\n    if (epoch + 1) % val_interval == 0:\n        model.eval()\n        with torch.no_grad():\n            val_images = None\n            val_labels = None\n            val_outputs = None\n            for val_data in val_loader:\n                val_images, val_labels = val_data[\"img\"].to(device), val_data[\"seg\"].to(device)\n                roi_size = (96, 96)\n                sw_batch_size = 4\n                val_outputs = sliding_window_inference(val_images, roi_size, sw_batch_size, model)\n                val_outputs = [post_trans(i) for i in decollate_batch(val_outputs)]\n                # compute metric for current iteration\n                dice_metric(y_pred=val_outputs, y=val_labels)\n            # aggregate the final mean dice result\n            metric = dice_metric.aggregate().item()\n            # reset the status for next validation round\n            dice_metric.reset()\n            metric_values.append(metric)\n            if metric > best_metric:\n                best_metric = metric\n                best_metric_epoch = epoch + 1\n                torch.save(model.state_dict(), \"../../best_metric_model_segmentation2d_dict.pth\")\n                print(\"saved new best metric model\")\n            print(\n                \"current epoch: {} current mean dice: {:.4f} best mean dice: {:.4f} at epoch {}\".format(\n                    epoch + 1, metric, best_metric, best_metric_epoch\n                )\n            )\n#             writer.add_scalar(\"val_mean_dice\", metric, epoch + 1)\n            # plot the last model output as GIF image in TensorBoard with the corresponding image and label\n#             plot_2d_or_3d_image(val_images, epoch + 1, writer, index=0, tag=\"image\")\n#             plot_2d_or_3d_image(val_labels, epoch + 1, writer, index=0, tag=\"label\")\n#             plot_2d_or_3d_image(val_outputs, epoch + 1, writer, index=0, tag=\"output\")\n\nprint(f\"train completed, best_metric: {best_metric:.4f} at epoch: {best_metric_epoch}\")\n# writer.close()","metadata":{"execution":{"iopub.status.busy":"2021-10-20T12:36:05.143321Z","iopub.execute_input":"2021-10-20T12:36:05.143766Z","iopub.status.idle":"2021-10-20T12:36:05.79793Z","shell.execute_reply.started":"2021-10-20T12:36:05.143735Z","shell.execute_reply":"2021-10-20T12:36:05.796677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir ../tmp/test\n\nfor img in ['7ae19de7bc2a.png', 'd48ec7815252.png', 'd8bfd1dafdc4.png']:\n\n    shutil.copy(f'../input/sartorius-cell-instance-segmentation/test/{img}', f'../tmp/test/{img}')","metadata":{"execution":{"iopub.status.busy":"2021-10-20T12:11:56.601642Z","iopub.execute_input":"2021-10-20T12:11:56.601945Z","iopub.status.idle":"2021-10-20T12:11:57.429487Z","shell.execute_reply.started":"2021-10-20T12:11:56.60189Z","shell.execute_reply":"2021-10-20T12:11:57.428398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_list = ['7ae19de7bc2a.png', 'd48ec7815252.png', 'd8bfd1dafdc4.png']\nfor test in test_list:\n    im, seg = create_test_image_2d(128, 128, num_seg_classes=1)\n    Image.fromarray((im * 255).astype(\"uint8\")).save(f'../../{test}')\n\n    images = sorted(glob(os.path.join('../../', \"*.png\")))\n    val_files = [{\"img\": img} for img in zip(images)]\n    val_transforms = Compose(\n    [\n        LoadImaged(keys=[\"img\"]),\n        AddChanneld(keys=[\"img\"]),\n        ScaleIntensityd(keys=[\"img\"]),\n        EnsureTyped(keys=[\"img\"]),\n    ]\n    )\n    val_ds = monai.data.Dataset(data=val_files, transform=val_transforms)\n    # sliding window inference need to input 1 image in every iteration\n    val_loader = DataLoader(val_ds, batch_size=1, num_workers=4, collate_fn=list_data_collate)\n    \n\n    model = monai.networks.nets.UNet(\n    spatial_dims=2,\n    in_channels=1,\n    out_channels=1,\n    channels=(16, 32, 64, 128, 256),\n    strides=(2, 2, 2, 2),\n    num_res_units=2,\n    ).to(device)\n\n    model.load_state_dict(torch.load(\"../../best_metric_model_segmentation2d_dict.pth\"))\n\n    model.eval()\n   \n        \n\n\n# val_images = cv2.imread('7ae19de7bc2a.png')\n\n# val_images = torch.Tensor(val_images).to(device)\n\n# print(val_images.shape)\n\n\n    with torch.no_grad():\n        for val_data in val_loader:\n            val_images = val_data[\"img\"].to(device)\n            # define sliding window size and batch size for windows inference\n            roi_size = (96, 96)\n            sw_batch_size = 4\n            val_outputs = sliding_window_inference(val_images, roi_size, sw_batch_size, model)\n            val_outputs = [post_trans(i) for i in decollate_batch(val_outputs)]\n#             print(len(val_outputs[0][0]))\n            val_outputs = val_outputs[0].numpy()\n            val_outputs = np.squeeze(val_outputs, axis=1)\n            val_outputs = val_outputs.transpose((1, 2, 0))\n            plt.figure(figsize=(4, 8))\n            plt.imshow(val_outputs)\n            plt.show()\n            \n#             val_outputs = [post_trans(i) for i in decollate_batch(val_outputs)]\n            \n#             print(val_outputs)","metadata":{"execution":{"iopub.status.busy":"2021-10-20T12:30:38.1371Z","iopub.execute_input":"2021-10-20T12:30:38.137406Z","iopub.status.idle":"2021-10-20T12:30:40.845564Z","shell.execute_reply.started":"2021-10-20T12:30:38.137368Z","shell.execute_reply":"2021-10-20T12:30:40.844471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}